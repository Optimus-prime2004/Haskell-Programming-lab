{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import datetime\n",
    "import wikipedia\n",
    "import webbrowser\n",
    "import os\n",
    "import smtplib\n",
    "\n",
    "# Initialize the text-to-speech engine\n",
    "engine = pyttsx3.init('sapi5')\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[0].id)\n",
    "\n",
    "def speak(audio):\n",
    "    engine.say(audio)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def wishMe():\n",
    "    hour = int(datetime.datetime.now().hour)\n",
    "    if hour >= 0 and hour < 12:\n",
    "        speak(\"Good Morning!\")\n",
    "    elif hour >= 12 and hour < 18:\n",
    "        speak(\"Good Afternoon!\")\n",
    "    else:\n",
    "        speak(\"Good Evening!\")\n",
    "\n",
    "    speak(\"I am Jarvis, your personal assistant. How may I assist you?\")\n",
    "\n",
    "def takeCommand():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        r.pause_threshold = 1\n",
    "        audio = r.listen(source)\n",
    "\n",
    "    try:\n",
    "        print(\"Recognizing...\")\n",
    "        query = r.recognize_google(audio, language='en-in')\n",
    "        print(f\"User said: {query}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Say that again please...\")\n",
    "        return \"None\"\n",
    "    return query\n",
    "\n",
    "if _name_ == \"_main_\":\n",
    "    wishMe()\n",
    "    while True:\n",
    "        query = takeCommand().lower()\n",
    "\n",
    "        #if 'wikipedia' in query:\n",
    "         #   speak('opening Wikipedia...')\n",
    "          #  speak('tell me the topic to search')\n",
    "            \n",
    "            #query = query.replace(\"wikipedia\", \"\")\n",
    "            #results = wikipedia.summary(query, sentences=2)\n",
    "            #speak(\"According to Wikipedia\")\n",
    "            #print(results)\n",
    "            #speak(results)\n",
    "        if 'what are the things that you can do' in query:\n",
    "            speak('According to my code,')\n",
    "            speak('I can detect object,send email,play music etc...')\n",
    "            speak('To do this,there are certain pivotal terms that are integral to this procedure')\n",
    "        elif 'tell me the terms' in query:\n",
    "            speak('say open yolo for object detection')\n",
    "            speak('say open google for opening google')\n",
    "            speak('say open youtube for opening youtube')\n",
    "            speak('say time now for telling time')\n",
    "            speak('say send email for sending email to others')\n",
    "            speak('say switch off for shut down')\n",
    "        elif 'open yolo' in query:\n",
    "            speak(\"Initiating object detection protocol\")\n",
    "            engine = pyttsx3.init('sapi5')\n",
    "            voices = engine.getProperty('voices')\n",
    "            engine.setProperty('voice', voices[0].id)\n",
    "\n",
    "\n",
    "            def speak(audio):\n",
    "                engine.say(audio)\n",
    "                engine.runAndWait()\n",
    "            def command():\n",
    "                r = sr.Recognizer()\n",
    "                speak('tell me access code to run')\n",
    "                with sr.Microphone() as source:\n",
    "                    print(\"Listening...\")\n",
    "                    r.pause_threshold = 1\n",
    "                    audio = r.listen(source)\n",
    "\n",
    "                try:\n",
    "                    print(\"Recognizing...\")\n",
    "                    query = r.recognize_google(audio, language='en-in')\n",
    "                    print(f\"User said: {query}\\n\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\"Say that again please...\")\n",
    "                    return \"None\"\n",
    "                return query\n",
    "\n",
    "            if _name_ == \"_main_\":\n",
    "                    query = command().lower()\n",
    "                    if 'spider' in query:\n",
    "                        import cv2\n",
    "                        import pyttsx3\n",
    "                        import numpy as np\n",
    "                        speak('Access code accepted')\n",
    "\n",
    "\n",
    "                        # Load the pre-trained YOLOv3 model\n",
    "                        net = cv2.dnn.readNetFromDarknet('yolov3.cfg', 'yolov3.weights')\n",
    "\n",
    "                        # Load the class names\n",
    "                        classes = []\n",
    "                        with open('coco.names', 'r') as f:\n",
    "                            classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "                        # Initialize the text-to-speech engine\n",
    "                        engine = pyttsx3.init()\n",
    "\n",
    "                        # Start capturing video from the webcam\n",
    "                        cap = cv2.VideoCapture(0)\n",
    "\n",
    "                        while True:\n",
    "                            # Read the current frame from the video stream\n",
    "                            ret, frame = cap.read()\n",
    "\n",
    "                            # Check if the frame is None (i.e., if the frame was not read successfully)\n",
    "                            if frame is None:\n",
    "                                print(\"Failed to read frame from video stream\")\n",
    "                                break\n",
    "\n",
    "                            # Perform object detection on the frame\n",
    "                            height, width, channels = frame.shape\n",
    "                            blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "                            net.setInput(blob)\n",
    "                            outs = net.forward(net.getUnconnectedOutLayersNames())\n",
    "\n",
    "                            # Get the bounding boxes, confidence scores, and class IDs\n",
    "                            class_ids = []\n",
    "                            confidences = []\n",
    "                            boxes = []\n",
    "                            for out in outs:\n",
    "                                for detection in out:\n",
    "                                    scores = detection[5:]\n",
    "                                    class_id = np.argmax(scores)\n",
    "                                    confidence = scores[class_id]\n",
    "                                    if confidence > 0.5:\n",
    "                                        center_x = int(detection[0] * width)\n",
    "                                        center_y = int(detection[1] * height)\n",
    "                                        w = int(detection[2] * width)\n",
    "                                        h = int(detection[3] * height)\n",
    "                                        x = int(center_x - w / 2)\n",
    "                                        y = int(center_y - h / 2)\n",
    "                                        class_ids.append(class_id)\n",
    "                                        confidences.append(float(confidence))\n",
    "                                        boxes.append([x, y, w, h])\n",
    "\n",
    "                            # Apply non-maximum suppression to remove overlapping bounding boxes\n",
    "                            indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "                            # Loop over the remaining bounding boxes after non-maximum suppression\n",
    "                            for i in indices:\n",
    "                                if i<len(class_ids):\n",
    "                                    box = boxes[i]\n",
    "                                    left, top, width, height = box\n",
    "                                    label = f'{classes[class_ids[i]]}: {confidences[i]:.2f}'\n",
    "\n",
    "                                # Convert the label to speech and speak it out\n",
    "                                    engine.say(label)\n",
    "                                    engine.runAndWait()\n",
    "\n",
    "                                # Print the label and confidence score in text format\n",
    "                                    print(label)\n",
    "\n",
    "                                # Draw the bounding box on the frame\n",
    "                                    cv2.rectangle(frame, (left, top), (left + width, top + height), (0, 255, 0), 2)\n",
    "\n",
    "                            # Display the resulting frame\n",
    "                            cv2.imshow('Object Detection', frame)\n",
    "\n",
    "                            # Break the loop if 'q' is pressed\n",
    "                            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                                break\n",
    "\n",
    "                        # Release the video capture and close the windows\n",
    "                        cap.release()\n",
    "                        cv2.destroyAllWindows()\n",
    "                    else:\n",
    "                        speak('Access code denied')\n",
    "            speak(\"object detection closed\")\n",
    "\n",
    "        elif 'open youtube' in query:\n",
    "            webbrowser.open(\"youtube.com\")\n",
    "            speak('opening youtube')\n",
    "\n",
    "        elif 'open google' in query:\n",
    "            webbrowser.open(\"google.com\")\n",
    "\n",
    "        elif 'play music' in query:\n",
    "            music_dir = 'C:\\\\Music'\n",
    "            songs = os.listdir(music_dir)\n",
    "            os.startfile(os.path.join(music_dir, songs[0]))\n",
    "\n",
    "        elif 'time now' in query:\n",
    "            strTime = datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
    "            speak(f\"The time is {strTime}\")\n",
    "\n",
    "        elif 'send email' in query:\n",
    "            try:\n",
    "                speak(\"What should I say?\")\n",
    "                content = takeCommand()\n",
    "                to = \"vvalliappan2004@gmail.com\"\n",
    "                sendEmail(to, content)\n",
    "                speak(\"Email has been sent!\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                speak(\"Sorry, I am unable to send the email at the moment.\")\n",
    "\n",
    "        elif 'switch off' in query:\n",
    "            speak(\"Goodbye!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import webbrowser\n",
    "\n",
    "def generate_summary(topic):\n",
    "    # Search for the topic on Google\n",
    "    query = \"https://www.google.com/search?q=\" + topic.replace(\" \", \"+\")\n",
    "    webbrowser.open(query)\n",
    "\n",
    "    # Use speech recognition to convert the summary to text\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Speak now...\")\n",
    "        audio = r.listen(source)\n",
    "\n",
    "    # Convert the speech to text\n",
    "    summary = r.recognize_google(audio)\n",
    "\n",
    "    # Use text-to-speech to provide the summary\n",
    "    tts = gTTS(text=summary, lang='en')\n",
    "    tts.save(\"summary.mp3\")\n",
    "    webbrowser.open(\"summary.mp3\")\n",
    "\n",
    "# Example usage\n",
    "generate_summary(\"python programming\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
